# 네거티브 샘플링

 - https://wikidocs.net/69141
 - https://heytech.tistory.com/354
 - https://techblog-history-younghunjo1.tistory.com/434

<br/>

## 네거티브 샘플링 등장 배경

네거티브 샘플링은 Word2Vec의 CBOW와 Skip-gram 방식에서 단어 갯수가 많아질수록 계산 복잡도가 증가하여 연산 속도가 저하된다는 한계점을 보완하기 위해 제언되었다.  
CBOW와 Skip-gram은 단어 갯수가 많아질수록 계산 복잡도 역시 높아지고, 이는 모델 학습 속도 저하를 유발한다.  

<br/>

## 네거티브 샘플링 개념

네거티브 샘플링은 Word2Vec이 학습 과정에서 전체 단어 집합이 아니라 일부 단어 집합에만 집중할 수 있도록 하는 방법이다. 가령, 현재 집중하고 있는 주변 단어가 '고양이'와 '귀여운' 이라고 했을 떄, 여기에 '돈가스', '컴퓨터' 같은 단어 집합에서 무작위로 선택된 주변 단어가 아닌 단어들을 일부 가져온다. 이렇게 하나의 중심 단어에 대해서 전체 단어 집합보다 훨씬 작은 단어 집합을 만들어놓고 마지막 단계를 이진 분류 문제로 변환한다. 주변 단어들을 긍정(Positive), 랜덤으로 샘플링 된 단어들을 부정(Negative)으로 레이블링한다면 이진 분류 문제를 위한 데이터셋이 된다. 이는 기존 단어 집합의 크기만큼의 선택지를 두고 다중 클래스 분류 문제를 풀던 Word2Vec보다 훨씬 연산량에서 효율적이다.  

<br/>

