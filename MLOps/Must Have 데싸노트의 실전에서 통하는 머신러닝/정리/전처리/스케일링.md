# 스케일링

스케일링은 입력 데이터의 범위를 조정하는 과정을 말합니다.  

 - 알고리즘의 안정성 향상: 일부 머신러닝 알고리즘은 입력 데이터의 스케일에 민감할 수 있습니다. 예를 들어, 서포트 벡터 머신(Support Vector Machine)이나 k-최근접 이웃(K-Nearest Neighbors) 알고리즘 등에서는 입력 특성 간의 스케일 차이가 예측 성능에 영향을 미칠 수 있습니다. 스케일링을 통해 이러한 알고리즘들이 안정적으로 동작하도록 할 수 있습니다.
 - 수렴 속도 향상: 일부 최적화 알고리즘은 입력 데이터의 스케일에 따라 수렴 속도가 크게 달라질 수 있습니다. 스케일이 큰 특성은 학습 중에 더 빠르게 변동하므로 수렴이 느려질 수 있습니다. 스케일을 조절하면 최적화 알고리즘이 더 빠르게 수렴할 수 있습니다.

<br/>

## 스케일링 종류

 - `표준화 스케일링`
    - 표준화는 각 특성에서 평균을 빼고 표준 편차로 나누어 특성의 평균이 0이고 표준 편차가 1이 되도록 만드는 과정
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(data)

scaled = scaler.transform(data)
scaled = pd.DataFrame(scaled, columns = data.columns) # Numpy -> Pandas
```

<br/>

 - `로버스트 스케일링`
    - 로버스트 스케일링의 주요 구성 요소는 중앙 위치의 측정 및 데이터 분산의 측정입니다. 일반적으로는 중앙 위치를 나타내기 위해 중앙값(median)을 사용하며, 데이터 분산을 나타내기 위해 사분위간범위(IQR, Interquartile Range)를 활용합니다.
    - 로버스트 스케일링은 일반적인 표준화나 정규화보다 이상치의 영향을 적게 받으며, 특히 중앙값과 IQR을 사용하기 때문에 중앙값 기반의 통계적 계산을 이용하여 안정성을 제공합니다. 이는 특히 이상치가 많거나 데이터가 비정상적인 분포를 갖는 경우에 유용합니다.
```python
from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
scaled = scaler.fit_transform(data) # fit + transform()
scaled = pd.DataFrame(scaled, columns = data.columns)
```

<br/>

 - `최소-최대 스케일링`
    - 다르게 주어진 피처의 변수를 모두 동일한 크기 단위로 비교하기 위해 값은 모두 최솟값을 0, 최댓값을 1로 변환하는 방법
```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled = scaler.fit_transform(data) # fit + transform()
scaled = pd.DataFrame(scaled, columns = data.columns)
```

<br/>

## 스케일링 종류별 특징

 - `표준화 스케일링`
    - 데이터에 아웃라이어가 존재할 때 아웃라이어의 영향을 받는다.
    - 평균 0, 분산 1이 되게끔 분포시키기 때문에, 데이터의 기존 분포 형태가 사라지고 정규분포를 따르는 결과물을 가져온다.
 - `로버스트 스케일링`
    - 데이터에 아웃라이어가 존재할 대, 아웃라이어의 영향을 받지 않는다.
    - 변환된 데이터의 범위는 표준화 스케일링이나 최소-최대 스케일링보다 넓게 나타난다.
 - `최소-최대 스케일링`
    - 표준화 스케일링과 마찬가지로 아웃라이어의 영향을 받는다.
    - 표준화, 로버스트 스케일링과 비교했을 때 데이터의 기존 분포를 가장 있는 그대로 담아내며 스케일만 변화시킨다. 데이터의 범위는 0~1로 나타난다.

<br/>

## 스케일링 주의점

 - `스케일링 대상에서 종속 변수를 제외한다.`
    - 예측하는 결과가 스케일링되는 경우 정확히 어떤 값을 예측해야 하는지 알 수 없다.
 - `스케일링 전에 훈련셋과 시험셋을 나누어야 한다.`
    - 스케일러를 통해 훈련셋으로 학습시키고, 해당 값을 활용하여 훈련셋과 시험셋을 변환한다.
    - 스케일러의 훈련셋을 기반으로 fit()을 수행하고, 해당 값을 사용하여 transform()으로 훈련셋과 시험셋을 각각 변환시켜준다.

<br/>

## 스케일링 적용하기


```python
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 와인 데이터 로드
wine_data = load_wine()
df_wines = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names) # 독립 변수
df_wines['class'] = wine_data.target # 종속 변수

# 학습셋과 시험셋 분리
X = df_wines.drop('class', axis=1)
y = df_wines['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)

# 스케일링
scaler = MinMaxScaler()
scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train) # 학습셋 변환
X_test_scaled = scaler.transform(X_test) # 시험셋 변환

# 모델링 및 예측
model = KNeighborsClassifier()      # 모델 생성
model.fit(X_train_scaled, y_train)  # 모델 학습
pred = knn.predict(X_test_scaled)   # 예측
accuracy_score(y_test, pred)
```

