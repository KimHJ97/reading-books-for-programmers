# 파일 입력

스프링 배치는 고성능 IO를 활용할 수 있도록 선언적인 Reader를 다수 제공한다.  

<br/>

## 플랫 파일

플랫 파일이란 한 개 또는 그 이상의 레코드가 포함된 특정 파일을 말한다.  
플랫 파일에는 팡리 내에 데이터의 포맷이나 의미를 정의하는 메타데이터가 없다.  

 - `FlatFileItemReader`
    - FlatFileItemReader는 메인 컴포넌트 두 개로 이뤄진다.
    - 하나는 읽어들일 대상 파일을 나타내는 Resource이고, 다른 하나는 LineMapper 인터페이스 구현체이다.
    - FlatFileItemReader를 사용하면 파일을 읽어들이는 작업과 관련된 여러 가지 애트리뷰트를 구성할 수 있다.
```
comments: 문자열 배열에 파일을 파싱할 때 건너뒤어야 할 주석 줄을 나타내는 접두어를 지정한다.
encoding: 파일에 사용된 문자열 인코딩
lineMapper: 이 클래스는 파일의 한 줄을 String으로 읽은 뒤 처리 대상인 도메인 객체(Item)로 변환된다.
linesToSkip: FlatFileItemReader가 파일을 파싱하기 전에 파일 시작부터 몇 줄을 건너뛸 것인지 지정한다.
recordSeparatorPolicy: 각 줄의 마지막을 정의하는 데 사용한다. 지정하지 않으면 개행 문자가 레코드의 끝 부분을 나타낸다.
resource: 읽을 대상 리소스
skippedLinesCallback: 줄을 건너뛸 때 호출되는 콜백 인터페이스. 건너뛴 모든 줄은 이 콜백으로 넘겨진다.
strict: true로 설정하면 리소스를 찾을 수 없을 때 Exception을 던진다.
saveState: 이 값이 true이면 재시작이 가능하도록 각 청크 처리 후에 ItemReader의 상태를 저장한다. 다중 쓰레드 환경에서는 false로 지정한다.
name: ExecutionContext에 저장되는 값의 고유 키를 생성하는 데 사용된다.
maxItemCount: 파일에서 읽어들일 아이템의 최대 개수를 나타낸다.
currentItemCount: 현재 조회 중인 아이템의 순번. 재시작 시 사용된다.
```

 - `LineMapper`
    - 파일을 읽을 때 파일에서 레코드 한 개에 해당하는 문자열이 LineMapper 구현체에 전달된다.
    - 기본적인 구현체는 DefaultLineMapper로 파일에서 읽은 원시 String을 대상으로 두 단계 처리를 거쳐 이후 처리에 사용할 도메인 객체로 변환한다.
        - __LineTokenizer__: 해당 줄을 파싱해 FieldSet으로 만든다. 레코드 내의 각 필드를 도메인 객체로 매핑하려면 해당 줄을 파싱해 각 필드를 나타내는 데이터의 모음으로 변환할 수 있어야 한다. 스프링 배치의 FieldSet은 한 줄에 해당하는 필드의 모음을 나타낸다.
        - __FieldSetMapper__: FieldSet을 도메인 객체로 매핑한다. LineTokenizer가 한 줄을 여러 필드로 나누고, 이제 각 입력 필드를 도메인 객체의 필드로 매핑할 수 있다.

<br/>

### 고정 너비 파일

 - `고객 파일 포맷 예제`
```
★ 포맷 형식
First Name(11): 이름
Middle Initial(1): 가운데 이름의 첫 글자
Last Name(10): 성
Address Number(4): 주소에서 건물 번호 부분
Street(20): 거주하는 거리 이름
City(16): 거주 도시
State(2): CA(캘리포니아), TX(텍사스) 등 주의 두 자리 약자
Zip Code(5): 우편번호

★ customer.txt 고정 너비 파일
----------------------------------------------------------
Aimee      CHoover    7341Vel Avenue          Mobile          AL35928
Jonas      UGilbert   8852In St.              Saint Paul      MN57321
Regan      MBaxter    4851Nec Av.             Gulfport        MS33193
Octavius   TJohnson   7418Cum Road            Houston         TX51507
..
```

 - `Customer 도메인 객체`
```Java
@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
public class Customer {

    private String middleInitial;
    private String lastName;
    private String addressNumber;
    private String street;
    private String city;
    private String state;
    private String zipCode;
}
```

 - `CustomerItemReader`
    - 매개변수로 대상 파일 경로(Resource)를 입력받고, 자동으로 Resource를 생성한다.
    - FixedLengthTokenizer 빌더는 각 줄을 파싱해 FieldSet으로 만드는 LineTokenizer의 구현체이다.
        - 레코드 내 각 컬럼의 이름을 지정하고, Range 객체의 배열을 지정한다.
        - Range 인스턴스는 파싱해야 할 컬럼의 시작 위치와 종료 위치를 나타낸다.
        - targetType 메서드를 호출하면 빌더가 BeanWrapperFieldSetMapper를 생성한다. 스프링 배치는 도메인 클래스에 값을 채울 때 FieldSetMapper에 구성된 컬럼의 이름을 사용하여 setter 메서드를 호출한다.
```Java
// Reader 정의
@Bean
@StepScope
public FlatFileItemReader<Customer> customerItemReader(
        @Value("#{jobParameters['customerFile']}") Resource inputFile) {
    
    return new FlatFileItemReaderBuilder<Customer>()
                .name("customerItemReader")
                .resource(inputFile)
                .fixedLength()
            .columns(new Range[]{
                new Range(1, 11), new Range(12, 12), new Range(13, 22),
                new Range(23, 26), new Range(27, 46), new Range(47, 62),
                new Range(63, 64), new Range(65, 69)
            })
            .names(new String[] {
                "firstName", "middleInitial", "lastName",
                "addressNumber", "street", "city",
                "state", "zipCode"
            })
            .targetType(Customer.class)
            .build();
}

// Writer 정의
@Bean
public ItemWriter<Customer> itemWriter() {
    return (items) -> items.forEach(System.out::println);
}

// Step 정의
@Bean
public Step copyFileStep() {
    return this.stepBuilderFactory.get("copyFileStep")
                .<Customer, Customer>chunk(10)
                .reader(customerItemReader(null))
                .writer(itemWriter())
                .build();
}

// Job 정의
// 실행: java -jar copyJob.jar customerFile=/path/to/customer/customerFixedWidth.txt
@Bean
public Job job() {
    return this.jobBuilderFactory.get("job")
                .start(copyFileStep())
                .build();
}
```

<br/>

### 필드가 구분자로 구분된 파일

구분자로 구분된 레코드를 읽는 방법은 고정 너비 레코드를 읽는 방법과 거의 유사하다.  
LineTokenizer를 사용해서 레코드를 FieldSet으로 변환하고, FieldSetMapper를 사용해서 FieldSet을 사용하려는 도메인 객체로 매핑한다.  
고정 너비 파일과 다른 점은 사전에 문자열 길이 범위를 지정했던 컬럼 관련 구성 대신에 구분자를 사용해 대상 파일을 파싱하도록 LineTokenizer 구현체 코드를 변경하면 된다.  

 - `구분자 포맷 예제`
```
★ 포맷 형식
First Name: 이름
Middle Initial: 가운데 이름의 첫 글자
Last Name: 성
Address Number: 주소에서 건물 번호 부분
Street: 거주하는 거리 이름
City: 거주 도시
State: CA(캘리포니아), TX(텍사스) 등 주의 두 자리 약자
Zip Code: 우편번호

★ customer.csv 구분자 파일
----------------------------------------------------------
Aimee,C,Hoover,7341,Vel Avenue,Mobile,AL,35928
Jonas,U,Gilbert,8852,In St.,Saint Paul,MN,57321
Regan,M,Baxter,4851,Nec Av.,Gulfport,MS,33193
..
```

 - `CustomerItemReader`
    - 구분자로 구분된 레코드를 처리할 때는 DelimitedLineTokenizer를 사용해 각 레코드를 FieldSet으로 변환한다.
    - DelimitedLineTokenizer는 두 가지 선택 항목을 제공한다.
        - 첫 번째는 구분자를 구성하는 항목으로 기본값은 쉼표(',') 이다.
        - 두 번째는 인용 문자로 사용할 값을 구성하는 항목으로 이 옵션을 사용하면 쌍따옴표('"') 대신 인용구를 지정하는 문자를 지정할 수 있다. 인용 문자는 파싱 결과에서 제외된다.
```Java
// Reader 정의
@Bean
@StepScope
public FlatFileItemReader<Customer> customerItemReader(
        @Value("#{jobParameters['customerFile']}")Resource inputFile) {

    return new FlatFileItemReaderBuilder<Customer>()
            .name("customerItemReader")
            .delimited()
            .names(new String[] {
                    "firstName",
                    "middleInitial",
                    "lastName",
                    "addressNumber",
                    "street",
                    "city",
                    "state",
                    "zipCode"
            })
            .targetType(Customer.class)
            .resource(inputFile)
            .build();
}

// Writer 정의
@Bean
public ItemWriter<Customer> itemWriter() {
    return (items) -> items.forEach(System.out::println);
}

// Step 정의
@Bean
public Step copyFileStep() {
    return this.stepBuilderFactory.get("copyFileStep")
            .<Customer, Customer>chunk(10)
            .reader(customerItemReader(null))
            .writer(itemWriter())
            .build();
}

// Job 정의
@Bean
public Job job() {
    return this.jobBuilderFactory.get("job")
            .start(copyFileStep())
            .build();
}
```

 - `CustomerFieldSetMapper`
    - FieldSetMapper 구현체를 만들어 파일 내의 필드를 도메인 객체의 필드로 커스텀하게 매핑할 수 있다.
```Java
public class CustomerFieldSetMapper implements FieldSetMapper<Customer> {

	public Customer mapFieldSet(FieldSet fieldSet) {
		Customer customer = new Customer();

		customer.setAddress(fieldSet.readString("addressNumber") +
				" " + fieldSet.readString("street"));
		customer.setCity(fieldSet.readString("city"));
		customer.setFirstName(fieldSet.readString("firstName"));
		customer.setLastName(fieldSet.readString("lastName"));
		customer.setMiddleInitial(fieldSet.readString("middleInitial"));
		customer.setState(fieldSet.readString("state"));
		customer.setZipCode(fieldSet.readString("zipCode"));

		return customer;
	}
}

// ItemReader 적용
@Bean
@StepScope
public FlatFileItemReader<Customer> customerItemReader(@Value("#{jobParameters['customerFile']}")Resource inputFile) {
    return new FlatFileItemReaderBuilder<Customer>()
            .name("customerItemReader")
            .delimited()
            .names(new String[] {
                    "firstName",
                    "middleInitial",
                    "lastName",
                    "addressNumber",
                    "street",
                    "city",
                    "state",
                    "zipCode"
            })
            .fieldSetMapper(new CustomerFieldSetMapper())
            .resource(inputFile)
            .build();
}
```

 - `CustomerFileLineTokenizer`
    - LineTokenizer 구현체를 만들어 원하는 대로 각 레코드를 파싱할 수 있다.
    - tokenizer 메서드는 각 레코드를 전달받은 뒤 이를 스프링에 구성한 구분자로 잘라 여러 필드로 만든다. 그다음 필드를 하나씩 돌면서 세 번쨰와 네 번째 필드를 묶어 단일 필드로 합친다.
```Java
public class CustomerFileLineTokenizer implements LineTokenizer {

	private String delimiter = ",";
	private String[] names = new String[] {"firstName",
			"middleInitial",
			"lastName",
			"address",
			"city",
			"state",
			"zipCode"};

	private FieldSetFactory fieldSetFactory = new DefaultFieldSetFactory();

	public FieldSet tokenize(String record) {

		String[] fields = record.split(delimiter);

		List<String> parsedFields = new ArrayList<>();

		for (int i = 0; i < fields.length; i++) {
			if (i == 4) {
				parsedFields.set(i - 1,
						parsedFields.get(i - 1) + " " + fields[i]);
			} else {
				parsedFields.add(fields[i]);
			}
		}

		return fieldSetFactory.create(parsedFields.toArray(new String [0]), names);
	}
}

// ItemReader 적용
@Bean
@StepScope
public FlatFileItemReader<Customer> customerItemReader(@Value("#{jobParameters['customerFile']}")Resource inputFile) {
    return new FlatFileItemReaderBuilder<Customer>()
            .name("customerItemReader")
            .lineTokenizer(new CustomerFileLineTokenizer())
            .fieldSetMapper(new CustomerFieldSetMapper())
            .resource(inputFile)
            .build();
}
```

<br/>

### 여러 가지 레코드 포맷

파일 내 각 레코드가 동일한 포맷인 경우에는 단순 구현체를 사용할 수 있었다.  
하지만, 여러 형식의 정보가 담긴 레코드가 넘어오는 경우에는 커스텀 LineTokenizer 하나를 새로 구현하는 방법을 이용할 수 있다.  
이 방법은 아래와 같은 문제점이 발생하게 된다.
 - 복잡도: 파일 내에 3가지, 4가지, 5가지 등 그 이상의 레코드 포맷이 존재하는 경우 복잡도가 증가한다.
 - 관심사 분리: LineTokenizer의 목적은 레코드를 파싱하는 것 그 이상 그 이하도 아니다. 때문에, 레코드 파싱을 넘어 어떤 레코드 유형인지를 판별하는 데 사용하는 것은 좋지 않다.

<br/>

스프링 배치는 이런 점을 감안해 별도의 LineMapper 구현체인 PatternMatchingCompositeLineMapper를 제공한다.  
DefaultLineMapper는 LineTokenizer 하나와 FileSetMapper 하나를 사용해 매핑 기능을 제공한다.  
반면, PatternMatchingCompositeLineMapper를 사용하면 여러 LineTokenizer로 구성된 Map을 선언할 수 있으며, 각 LineTokenizer가 필요로 하는 여러 FieldSetMapper로 구성된 Map을 선언할 수 있다.  
각 맵의 키는 레코드의패턴이다. LineMapper는 이 패턴을 이용해서 각 레코드를 어떤 LineTokenizer로 파싱할지 식별한다.  

<br/>

 - `변경된 고객 정보 입력 파일`
    - 파일은 쉼표(,)로 필드가 구분된 레코드가 두 가지 포맷으로 구성된다.
    - CUST 접두어로 시작하는 고객 정보 포맷과 TRANS 접두어로 시작하는 거래 정보 포맷
```
CUST,Warren,Q,Darrow,8272 4th Street,New York,IL,76091
TRANS,1165965,2011-01-22 00:13:29,51.43
CUST,Ann,V,Gates,9247 Infinite Loop Drive,Hollywood,NE,37612
CUST,Erica,I,Jobs,8875 Farnam Street,Aurora,IL,36314
TRANS,8116369,2011-01-21 20:40:52,-14.83
TRANS,8116369,2011-01-21 15:50:17,-45.45
```

 - `Transaction` 도메인 객체
```Java
public class Transaction {

	private String accountNumber;
	private Date transactionDate;
	private Double amount;

	private DateFormat formatter = new SimpleDateFormat("MM/dd/yyyy");

    // Getter & Setter 
    ..

	public String getDateString() {
		return this.formatter.format(this.transactionDate);
	}

    // ToString
    ..

}
```

 - 여러 레코드 포맷이 포함된 MultiFormatJob 구성
```Java
@EnableBatchProcessing
@SpringBootApplication
public class MultiFormatJob {

	@Autowired
	private JobBuilderFactory jobBuilderFactory;

	@Autowired
	private StepBuilderFactory stepBuilderFactory;

    // ItemReader 정의
	@Bean
	@StepScope
	public FlatFileItemReader customerItemReader(
			@Value("#{jobParameters['customerFile']}")Resource inputFile) {

		return new FlatFileItemReaderBuilder<Customer>()
				.name("customerItemReader")
				.lineMapper(lineTokenizer())
				.resource(inputFile)
				.build();
	}

	@Bean
	public PatternMatchingCompositeLineMapper lineTokenizer() {
        // LineTokenizers
		Map<String, LineTokenizer> lineTokenizers = new HashMap<>(2);

		lineTokenizers.put("CUST*", customerLineTokenizer()); // 레코드가 CUST로 시작하면 customerLineTokenizer로 파싱
		lineTokenizers.put("TRANS*", transactionLineTokenizer()); // 레코드가 TRANS로 시작하면 transactionLineTokenizer로 파싱

        // FieldSetMappers
		Map<String, FieldSetMapper> fieldSetMappers = new HashMap<>(2);

		BeanWrapperFieldSetMapper<Customer> customerFieldSetMapper = new BeanWrapperFieldSetMapper<>();
		customerFieldSetMapper.setTargetType(Customer.class);

		fieldSetMappers.put("CUST*", customerFieldSetMapper);
		fieldSetMappers.put("TRANS*", new TransactionFieldSetMapper());

        // PatternMatchingCompositeLineMapper
		PatternMatchingCompositeLineMapper lineMappers = new PatternMatchingCompositeLineMapper();

		lineMappers.setTokenizers(lineTokenizers);
		lineMappers.setFieldSetMappers(fieldSetMappers);

		return lineMappers;
	}

    // TRANS 접두어로 시작하는 레코드 정보 Tokenizer
	@Bean
	public DelimitedLineTokenizer transactionLineTokenizer() {
		DelimitedLineTokenizer lineTokenizer = new DelimitedLineTokenizer();

		lineTokenizer.setNames("prefix",
				"accountNumber",
				"transactionDate",
				"amount");

		return lineTokenizer;
	}

    // CUST 접두어로 시작하는 레코드 정보 Tokenizer
	@Bean
	public DelimitedLineTokenizer customerLineTokenizer() {
		DelimitedLineTokenizer lineTokenizer = new DelimitedLineTokenizer();

		lineTokenizer.setNames("firstName",
				"middleInitial",
				"lastName",
				"address",
				"city",
				"state",
				"zipCode");

		lineTokenizer.setIncludedFields(1, 2, 3, 4, 5, 6, 7);

		return lineTokenizer;
	}

    // ItemWriter 정의
	@Bean
	public ItemWriter itemWriter() {
		return (items) -> items.forEach(System.out::println);
	}

    // Step 정의
	@Bean
	public Step copyFileStep() {
		return this.stepBuilderFactory.get("copyFileStep")
				.<Customer, Customer>chunk(10)
				.reader(customerItemReader(null))
				.writer(itemWriter())
				.build();
	}

    // Job 정의
	@Bean
	public Job job() {
		return this.jobBuilderFactory.get("job")
				.start(copyFileStep())
				.build();
	}
}

// TransactionFieldSetMapper
public class TransactionFieldSetMapper implements FieldSetMapper<Transaction> {

	public Transaction mapFieldSet(FieldSet fieldSet) {
		Transaction trans = new Transaction();

		trans.setAccountNumber(fieldSet.readString("accountNumber"));
		trans.setAmount(fieldSet.readDouble("amount"));
		trans.setTransactionDate(fieldSet.readDate("transactionDate",
				"yyyy-MM-dd HH:mm:ss"));

		return trans;
	}
}
```

### 여러 줄에 걸친 레코드

파일에서 읽어들인 레코드 사이에 관계가 있을 수 있다.  
이전 예제에서 거래 내역 레코드가 해당 레코드 바로 앞에 나왔던 고객 레코드의 하위 정보에 해당하는 레코드인 경우 각 레코드를 독립적으로 처리하는 대신 Customer 객체가 내부에 Transaction 객체의 컬렉션을 가지고 있도록 처리하는 것이 더 상식적이다.  


 - `Customer 도메인 객체`
```Java
@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
public class Customer {

    private String middleInitial;
    private String lastName;
    private String addressNumber;
    private String street;
    private String city;
    private String state;
    private String zipCode;

    private List<Transaction> transactions;
}
```

 - `CustomerFileReader`
    - read 메서드는 하위에 거래 내역 레코드가 포함된 Customer 아이템을 하나 읽어들이고 조합하는 역할을 한다.
        - 먼저, 파일에서 고객 레코드를 읽어들인다.
        - 그리고 다음 고객 레코드를 만나기 전까지 현재 처리 중인 고객 레코드와 관련된 거래 내역 레코드를 한 줄씩 계속 읽어들인다.
    - peek 메서드는 현재 처리 중인 Customer를 처리하는 과정에서 레코드를 미리 읽어 놓는 데 사용한다.
        - peek 메서드는 현재 레코드를 캐시에 저장한다.
        - 레코드를 읽어들였지만 아직 처리하지 않아싸면 peek 메서드는 동일한 레코드를 다시 반환한다.
        - 레코드가 처리되면 다음 레코드를 읽어들인다.
```Java
public class CustomerFileReader implements ResourceAwareItemReaderItemStream<Customer> {

	private Object curItem = null;

	private ResourceAwareItemReaderItemStream<Object> delegate;

	public CustomerFileReader(ResourceAwareItemReaderItemStream<Object> delegate) {
		this.delegate = delegate;
	}

	public Customer read() throws Exception {
		if(curItem == null) {
			curItem = delegate.read(); // 고객 레코드 읽기
		}

		Customer item = (Customer) curItem;
		curItem = null;

		if(item != null) {
			item.setTransactions(new ArrayList<>());

			while(peek() instanceof Transaction) { // 다음 레코드를 읽고, 거래 레코드인 경우 true
				item.getTransactions().add((Transaction) curItem);
				curItem = null;
			}
		}

		return item;
	}

	private Object peek() throws Exception {
		if (curItem == null) {
			curItem = delegate.read();
		}
		return curItem;
	}

	public void close() throws ItemStreamException {
		delegate.close();
	}

	public void open(ExecutionContext arg0) throws ItemStreamException {
		delegate.open(arg0);
	}

	public void update(ExecutionContext arg0) throws ItemStreamException {
		delegate.update(arg0);
	}

	@Override
	public void setResource(Resource resource) {
		this.delegate.setResource(resource);
	}
}
```

 - `MultiLineJob`
```Java
@EnableBatchProcessing
@SpringBootApplication
public class MultiLineJob {

	@Bean
	@StepScope
	public FlatFileItemReader customerItemReader(
			@Value("#{jobParameters['customerFile']}")Resource inputFile) {

		return new FlatFileItemReaderBuilder<Customer>()
				.name("customerItemReader")
				.lineMapper(lineTokenizer()) // PatternMatchingCompositeLineMapper
				.resource(inputFile)
				.build();
	}

	@Bean
	public CustomerFileReader customerFileReader() {
		return new CustomerFileReader(customerItemReader(null));
	}

    // PatternMatchingCompositeLineMapper & transactionLineTokenizer & customerLineTokenizer 정의
    ..

    // Writer & Step & Job 정의
    ..
	@Bean
	public Step copyFileStep() {
		return this.stepBuilderFactory.get("copyFileStep")
				.<Customer, Customer>chunk(10)
				.reader(customerFileReader())
				.writer(itemWriter())
				.build();
	}
}
```

<br/>

### 여러 개의 소스

스프링 배치는 동일한 포맷으로 작성된 복수 개의 파일을 읽어들이는  MultiResourceItemReader라는 ItemReader를 제공한다.  

 - MultiFileJob
```Java
@EnableBatchProcessing
@SpringBootApplication
public class MultiFileJob {

	..

	@Bean
	@StepScope
	public FlatFileItemReader customerItemReader() {

		return new FlatFileItemReaderBuilder<Customer>()
				.name("customerItemReader")
				.lineMapper(lineTokenizer())
				.build();
	}

	// MultiResourceItemReader
	@Bean
	@StepScope
	public MultiResourceItemReader multiCustomerReader(@Value("#{jobParameters['customerFile']}")Resource[] inputFiles) {
		return new MultiResourceItemReaderBuilder<>()
				.name("multiCustomerReader")
				.resources(inputFiles)
				.delegate(customerFileReader())
				.build();
	}

	@Bean
	public CustomerFileReader customerFileReader() {
		return new CustomerFileReader(customerItemReader());
	}

    // PatternMatchingCompositeLineMapper & transactionLineTokenizer & customerLineTokenizer 정의
    ..

    // Writer & Step & Job 정의

}
```

<br/>

## XML

XML은 파일 내 데이터를 설명할 수 있는 태그를 사용해서 파일에 포함된 데이터를 설명한다.  
XML 파서로는 DOM 파서와 SAX 파서를 많이 사용하는데, DOM 파서는 노드를 탐색할 수 있도록 전체 파일을 메모리에 트리 구조로 읽어들인다. 이러한 접근법은 성능상 큰 부하가 발생할 수 있어 배치 처리에는 유용하지 않다. 배치에서는 SAX 파서를 이용하며, SAX는 특정 엘리먼트를 만나면 이벤트를 발생시키는 이벤트 기반 파서이다.  
스프링 배치에서는 StAX 파서를 사용하는데, StAX 파서도 SAX 파서와 비슷한 이벤트 기반 파서이지만, XML 문서 내 각 섹션을 독립적으로 파싱하는 기능을 제공한다.  

 - `customer.xml`
	- 고객 파일은 각 고객 섹션이 모인 컬렉션 구조로 구성돼 있다. 각 고객 섹션에는 거래 섹션의 컬렉션이 포함돼 있다.
	- 플랫 파일을 처리할 때는 스프링 배치가 각 줄을 FieldSet으로 파싱했지만, XML을 처리할 때는 사용자가 정의한 XML 프래그먼트를 도메인 객체로 파싱한다.
	- 스프링 배치는 파일 내에서 미리 지정한 XML 프래그먼트를 만날 때마다 이를 단일 레코드로 간주하고 처리 대상 아이템으로 변환한다.
```XML
<customers>
	<customer>
		<firstName>Laura</firstName>
		<middleInitial>O</middleInitial>
		<lastName>Minella</lastName>
		<address>2039 Wall Street</address>
		<city>Omaha</city>
		<state>IL</state>
		<zipCode>35446</zipCode>
		<transactions>
			<transaction>
				<accountNumber>829433</accountNumber>
				<transactionDate>2010-10-14 05:49:58</transactionDate>
				<amount>26.08</amount>
			</transaction>
		</transactions>
	</customer>
	<customer>
		<firstName>Michael</firstName>
		<middleInitial>T</middleInitial>
		<lastName>Buffett</lastName>
		<address>8192 Wall Street</address>
		<city>Omaha</city>
		<state>NE</state>
		<zipCode>25372</zipCode>
		<transactions>
			<transaction>
				<accountNumber>8179238</accountNumber>
				<transactionDate>2010-10-27 05:56:59</transactionDate>
				<amount>-91.76</amount>
			</transaction>
			<transaction>
				<accountNumber>8179238</accountNumber>
				<transactionDate>2010-10-06 21:51:05</transactionDate>
				<amount>-25.99</amount>
			</transaction>
		</transactions>
	</customer>
</customers>
```

 - `pom.xml`
	- 스프링이 제공하는 Jaxb2Marshaller 구현체를 사용하기 위해서는 의존성을 추가해야 한다.
```XML
<dependency>
	<groupId>org.springframework</groupId>
	<artifactId>spring-oxm</artifactId>
</dependency>
<dependency>
	<groupId>javax.xml.bind</groupId>
	<artifactId>jaxb-api</artifactId>
	<version>2.2.11</version>
</dependency>
<dependency>
	<groupId>com.sun.xml.bind</groupId>
	<artifactId>jaxb-core</artifactId>
	<version>2.2.11</version>
</dependency>
<dependency>
	<groupId>com.sun.xml.bind</groupId>
	<artifactId>jaxb-impl</artifactId>
	<version>2.2.11</version>
</dependency>
<dependency>
	<groupId>javax.activation</groupId>
	<artifactId>activation</artifactId>
	<version>1.1.1</version>
</dependency>
```

 - `Customer`
	- JAXB가 XML 태그와 매핑할 수 있도록 클래스에 애너테이션을 추가해서 매핑 대상임을 나타낸다.
```Java
@XmlRootElement
public class Customer {
	private String firstName;
	private String middleInitial;
	private String lastName;
	private String address;
	private String city;
	private String state;
	private String zipCode;

	private List<transaction> transactions;

	public Customer() {}

	@XmlElementWrapper(name = "transactions")
	@XmlElement(name = "transaction")
	public void setTransactions(List<Transactions> transations) {
		this.transactions = transactions;
	}
}
```

 - `XmlJob`
	- XML 입력 파일을 파싱하려면 스프링 배치가 제공하는 StacEventItemReader를 사용한다.
	- StaxEventItemReader를 사용하기 위해서 XML 프래그먼트의 루트 엘리먼트 이름을 정의한다. 이는 XML 내에서 아이템으로 취급할 각 XML 프래그먼트의 루트 엘리먼트를 식별하는 데 사용된다.
```Java
@EnableBatchProcessing
@SpringBootApplication
public class XmlJob {

	@Autowired
	private JobBuilderFactory jobBuilderFactory;

	@Autowired
	private StepBuilderFactory stepBuilderFactory;

	@Bean
	@StepScope
	public StaxEventItemReader<Customer> customerFileReader(
			@Value("#{jobParameters['customerFile']}") Resource inputFile) {

		return new StaxEventItemReaderBuilder<Customer>()
				.name("customerFileReader")
				.resource(inputFile)
				.addFragmentRootElements("customer")
				.unmarshaller(customerMarshaller())
				.build();
	}

	@Bean
	public Jaxb2Marshaller customerMarshaller() {
		Jaxb2Marshaller jaxb2Marshaller = new Jaxb2Marshaller();
		jaxb2Marshaller.setClassesToBeBound(Customer.class, Transaction.class);

		return jaxb2Marshaller;
	}

	@Bean
	public ItemWriter itemWriter() {
		return (items) -> items.forEach(System.out::println);
	}

	@Bean
	public Step copyFileStep() {
		return this.stepBuilderFactory.get("copyFileStep")
				.<Customer, Customer>chunk(10)
				.reader(customerFileReader(null))
				.writer(itemWriter())
				.build();
	}

	@Bean
	public Job job() {
		return this.jobBuilderFactory.get("job")
				.start(copyFileStep())
				.build();
	}


	public static void main(String[] args) {
		List<String> realArgs = Collections.singletonList("customerFile=/input/customer.xml");

		SpringApplication.run(XmlJob.class, realArgs.toArray(new String[1]));
	}

}
```

<br/>

## JSON

스프링 배치에서는 JSON 데이터를 파싱해서 읽을 수 있도록 Jackson과 Gson을 이용하는 두 가지 인터페이스 구현체를 제공한다.  

```Java
@EnableBatchProcessing
@SpringBootApplication
public class JsonJob {

	@Bean
	@StepScope
	public JsonItemReader<Customer> customerFileReader(
			@Value("#{jobParameters['customerFile']}") Resource inputFile) {

		ObjectMapper objectMapper = new ObjectMapper();
		objectMapper.setDateFormat(new SimpleDateFormat("yyyy-MM-dd hh:mm:ss"));

		JacksonJsonObjectReader<Customer> jsonObjectReader = new JacksonJsonObjectReader<>(Customer.class);
		jsonObjectReader.setMapper(objectMapper);

		return new JsonItemReaderBuilder<Customer>()
				.name("customerFileReader")
				.jsonObjectReader(jsonObjectReader)
				.resource(inputFile)
				.build();
	}

	// Writer & Step & Job

}
```
